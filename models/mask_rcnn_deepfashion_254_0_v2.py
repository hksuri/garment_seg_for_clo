# -*- coding: utf-8 -*-
"""Mask_rcnn_deepFashion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o1FpNzDrjEWUo8KEx7e_N7f7oIGnfWAn
"""


"""Reference: https://towardsdatascience.com/train-mask-rcnn-net-for-object-detection-in-60-lines-of-code-9b6bbff292c3

https://medium.com/analytics-vidhya/a-simple-guide-to-maskrcnn-custom-dataset-implementation-27f7eab381f2
"""

import random
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
import numpy as np
import torch.utils.data
import cv2
import torchvision.models.segmentation
import torch
import os
from matplotlib.path import Path
import json
from os.path import exists
import pandas as pd
import utils_deepfashion
import sys

file_name= sys.argv[0]
file_name = file_name.split('/')[-1]
file_name = file_name.split('.')[0]

driver_location= 'cluster'
dict_directory={}

root_project = dict_directory[driver_location]
os.chdir(root_project)

# !pip install wget
# import wget
# URL = 'https://zenodo.org/record/4736111/files/LabPicsChemistry.zip?download=1'
# response = wget.download(URL, "labpics.zip")

# !unzip '/content/drive/MyDrive/CS444_Final_Project/Nidia/labpics.zip'
# root_project= root #'/content/drive/MyDrive/CS444_Final_Project/Nidia'



root_dataset = os.path.join(root_project, 'train')#'/content/drive/MyDrive/deepfashion'
train_root =  root_dataset  #os.path.join(root_dataset,'train' )
PATH_TRAIN_images= os.path.join(train_root,'image')
PATH_TRAIN_annotations= (os.path.join(train_root, 'annos'))


PATH_EVALUATION_images= os.path.join(root_project,'validation/image') ## FOR NOW
PATH_EVALUATION_annotations= (os.path.join(root_project, 'validation/annos'))  ## FOR NOW
N_images_evaluation= len(os.listdir(PATH_EVALUATION_images))
sample_evaluation= 300


n_epochs=100
imageSize= (254,254)
num_classes=13
batch_size= 8
list_images= os.listdir(PATH_TRAIN_images)
list_annotations= os.listdir(PATH_TRAIN_annotations)
N_images= len(list_images)



data_loader_params= {}
data_loader_params['list_images']= list_images
data_loader_params['PATH_TRAIN_images']= PATH_TRAIN_images
data_loader_params['PATH_TRAIN_annotations']= PATH_TRAIN_annotations
data_loader_params['imageSize']= imageSize



device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
print (device)   # train on the GPU or on the CPU, if a GPU is not available
model_directory = os.path.join(root_project, file_name)   ## change the name!!!

try:
   os.mkdir(model_directory)
   print('myDirectory created')
except FileExistsError:
   print('myDirectory already exists')


LOSS_PATH= os.path.join(model_directory,'loss.csv')
if exists(LOSS_PATH):
  summary_loss= pd.read_csv(LOSS_PATH)
  start_epoch= len(summary_loss)

else:
  summary_loss= pd.DataFrame()
  start_epoch= 0

model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(pretrained=True,trainable_backbone_layers=0)  # load an instance segmentation model pre-trained pre-trained on COCO
in_features = model.roi_heads.box_predictor.cls_score.in_features  # get number of input features for the classifier
model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes=num_classes+1)  # replace the pre-trained head with a new one
model.to(device)# move model to the right devic

last_checkpoint_path = os.path.join(model_directory, f"last_checkpoint_{file_name}.torch")
if exists(last_checkpoint_path):
    model.load_state_dict(torch.load(last_checkpoint_path))

optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)
model.train()
best_loss= float("inf")
best_iou = float('-inf')
best_map = float("-inf")
for epoch in range(start_epoch, n_epochs):
        epoch_loss= []
        epoch_summary=pd.DataFrame()
        permut= np.random.permutation(N_images)
        model.train()
        for i in range(0,int(N_images/10),batch_size): ## REMOVE THE /2. I am doing this because it is taking for ever to debug.
              to_load= permut[i:i+batch_size]
              images, targets = utils_deepfashion.load_images(to_load, **data_loader_params)
              images = list(image.to(device) for image in images)
              targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
              optimizer.zero_grad()
              loss_dict = model(images, targets)
              
              losses = sum(loss for loss in loss_dict.values())
              losses.backward()
              optimizer.step()
              
              df= utils_deepfashion.dict_loss_dataFrame(loss_dict)
              df['epoch']= epoch
              epoch_summary= pd.concat([epoch_summary, df])
              epoch_loss.append(losses.item())

        # print(epoch,'loss:', losses.item())
        mean_loss= np.mean(epoch_loss)
        print(epoch,'loss:', mean_loss)
        if mean_loss < best_loss:
          best_loss= mean_loss
          torch.save(model.state_dict(), os.path.join(model_directory, f"best_checkpoint_{file_name}.torch"))
  
        torch.save(model.state_dict(), os.path.join(model_directory, f"last_checkpoint_{file_name}.torch"))
        if epoch%5==0:
            torch.save(model.state_dict(), os.path.join(model_directory, f'{epoch}_ checkpoint_{file_name}.torch'))
        

        map_ = 'None'
        iou_ = 'None'
        if epoch%5==0:
            batch_= np.random.permutation(N_images_evaluation)
            map_= []
            iou_=[]
            for i in range(0,4500,sample_evaluation):
                idxs = batch_[i:i+sample_evaluation]
                map_i,iou_i = utils_deepfashion.evaluate(model, 
                                                PATH_evaluation_annotation=PATH_EVALUATION_annotations, 
                                                PATH_evaluation_images=PATH_EVALUATION_images, imageSize=imageSize,
                                                device='cuda', idxs=idxs )
                
                map_.append(np.mean(map_i))
                iou_.append(np.mean(iou_i))

            map_= np.mean(map_)
            iou_ = np.mean(iou_)

            if map_>best_map:
                best_map=map_
        
            if iou_ >best_iou:
                best_iou = iou_ 
                torch.save(model.state_dict(), os.path.join(model_directory, f"best_iou_checkpoint_{file_name}.torch")) 

        torch.save(model.state_dict(), os.path.join(model_directory, f"last_checkpoint_{file_name}.torch"))
        df =pd.DataFrame(epoch_summary.mean(axis=0)).T
        df['best_map'] = map_
        df['best_iou']= best_iou
        df['mean_loss']= mean_loss
        df['map_val'] = map_
        df['iou_val']= iou_ 
        df['file_name'] = file_name
        

        summary_loss= pd.concat([summary_loss, df])
        summary_loss.to_csv(LOSS_PATH)


